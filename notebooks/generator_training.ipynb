{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocessed_train.csv')\n",
    "valid = pd.read_csv('preprocessed_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 128\n",
    "valid_size= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = np.arange(len(train))\n",
    "num_valid = np.arange(len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train(idx, batch_size):\n",
    "    x = []\n",
    "    steps_done = idx * batch_size\n",
    "    indexes = num_train[steps_done : (idx + 1) * batch_size]\n",
    "    for i in indexes:\n",
    "        img_dir = 'processed_train/' + train.loc[i, 'FILENAME']\n",
    "        image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        x.append(image)\n",
    "    x = np.array(x).reshape(-1, 256, 64, 1)\n",
    "    label_len = np.zeros([batch_size, 1])\n",
    "    input_len = np.ones([batch_size, 1]) * (num_of_timestamps-2)\n",
    "    output = np.zeros([batch_size])\n",
    "    y = np.ones([batch_size, max_str_len]) * -1\n",
    "\n",
    "    for index, i in enumerate(indexes):\n",
    "        label_len[index] = len(train.loc[i, 'IDENTITY'])\n",
    "        y[index, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])\n",
    "\n",
    "    return [x, label_len, input_len, output, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_valid(idx, batch_size):\n",
    "    x = []\n",
    "    steps_done = idx * batch_size\n",
    "    indexes = num_valid[steps_done : (idx + 1) * batch_size]\n",
    "    for i in indexes:\n",
    "        img_dir = 'processed_valid/' + valid.loc[i, 'FILENAME']\n",
    "        image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        x.append(image)\n",
    "    x = np.array(x).reshape(-1, 256, 64, 1)\n",
    "    label_len = np.zeros([batch_size, 1])\n",
    "    input_len = np.ones([batch_size, 1]) * (num_of_timestamps-2)\n",
    "    output = np.zeros([batch_size])\n",
    "    y = np.ones([batch_size, max_str_len]) * -1\n",
    "\n",
    "    for index, i in enumerate(indexes):\n",
    "        label_len[index] = len(valid.loc[i, 'IDENTITY'])\n",
    "        y[index, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])\n",
    "\n",
    "    return [x, label_len, input_len, output, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_gen(batch_size, steps):\n",
    "    idx=1\n",
    "    while True: \n",
    "        x, label_len, input_len, output, y = gen_train(idx - 1, batch_size)\n",
    "        yield [x, y, input_len, label_len], output\n",
    "        if idx<steps:\n",
    "            idx+=1\n",
    "        else:\n",
    "            idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_batch_gen(batch_size, steps):\n",
    "    idx=1\n",
    "    while True: \n",
    "        x, label_len, input_len, output, y = gen_valid(idx - 1, batch_size)\n",
    "        yield [x, y, input_len, label_len], output\n",
    "        if idx<steps:\n",
    "            idx+=1\n",
    "        else:\n",
    "            idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = int(np.floor(len(train) / train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-'` \"\n",
    "max_str_len = 34\n",
    "num_of_characters = len(alphabets) + 1\n",
    "num_of_timestamps = 64\n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True, name='lstminner1'), name = 'lstm1')(inner) # try gru instead of lstm\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True, name='lstminner2'), name = 'lstm2')(inner)\n",
    "\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.0001)\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('accuracy_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "mc2 = ModelCheckpoint('loss_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = model_final.fit(train_batch_gen(train_size, num_iterations), validation_data=valid_batch_gen(valid_size, num_iterations), steps_per_epoch=num_iterations,\n",
    "                            validation_steps=num_iterations, epochs=105, shuffle=True, callbacks=[es, mc, mc2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(myModel.history['loss'], label='train loss')\n",
    "plt.plot(myModel.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig('LossVal_loss.jpg')\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(myModel.history['accuracy'], label='train acc')\n",
    "plt.plot(myModel.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('AccVal_acc.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"gpu_acceleration/results/accuracy_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = []\n",
    "\n",
    "for i in range(len(valid)):\n",
    "    img_dir = 'processed_valid/' + valid.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    valid_x.append(image)\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(valid_x)\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], greedy=True)[0][0])\n",
    "prediction = []\n",
    "for i in range(len(valid_x)):\n",
    "    prediction.append(num_to_label(decoded[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = valid.loc[0:len(valid_x), 'IDENTITY']\n",
    "correct_char = 0\n",
    "total_char = 0\n",
    "correct = 0\n",
    "for i in range(len(valid_x)):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "    \n",
    "    for j in range(min(len(tr), len(pr))):\n",
    "        if tr[j] == pr[j]:\n",
    "            correct_char += 1\n",
    "            \n",
    "    if pr == tr :\n",
    "        correct += 1 \n",
    "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
    "print('Correct words predicted      : %.2f%%' %(correct*100/len(valid_x)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae356e75d36f58ae0a0fbe212380b20cef846d46894bb949c9e4d7fe5e6076c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
